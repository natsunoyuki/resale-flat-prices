{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resale Rent Data Pipeline\n",
    "\n",
    "Loads the published resale data from CSV files to processing and saving them as a ZIP file.\n",
    "\n",
    "1. Load and process CSV files published on https://data.gov.sg/collections/189/view.\n",
    "2. Load any existing geocoded addresses.\n",
    "3. Update geocoded addresses.\n",
    "4. Make H3 geometries.\n",
    "5. Output data to disk for further downstream analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "\n",
    "# Local imports.\n",
    "from property_prices.csv_data.resale_csv_data import ResaleCsvData\n",
    "from property_prices.csv_data.rent_csv_data import RentCsvData\n",
    "from property_prices.geocode.geocoded_addresses import GeocodedAddresses\n",
    "\n",
    "\n",
    "# Data directories.\n",
    "csv_data_dir = Path(\"../data/ResaleFlatPrices/\")\n",
    "rent_data_csv_file = Path(\"../data/RentingOutofFlats/RentingOutofFlats2024CSV.csv\")\n",
    "\n",
    "processed_data_dir = Path(\"../data/processed_data/\")\n",
    "\n",
    "hdb_addresses_json_file = Path(\"hdb_addresses.json\")\n",
    "\n",
    "output_resale_geojson_file = Path(\"resale-flat-prices.parquet\")\n",
    "output_rent_geojson_file = Path(\"rent-prices.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process resale flat prices CSV files published on https://data.gov.sg/collections/189/view.\n",
    "print(\"Loading resale flat prices CSV data from {}.\".format(csv_data_dir))\n",
    "csv_data = ResaleCsvData(csv_data_dir, wanted_columns = \"default\")\n",
    "csv_data.load_csv_files()\n",
    "csv_data.compile_csv_data()\n",
    "csv_data.process_csv_data()\n",
    "repaired_rows = csv_data.check_and_repair_datetimes()\n",
    "if len(repaired_rows) > 0:\n",
    "    print(\"    Repaired datetimes at rows {}.\".format(repaired_rows))\n",
    "print(\"    Loaded and compiled resale flat prices CSV data with shape {}.\".format(csv_data.df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process raw rent CSV files published on https://data.gov.sg/datasets/d_c9f57187485a850908655db0e8cfe651/view\n",
    "print(\"Loading rent data CSV data from {}.\".format(rent_data_csv_file))\n",
    "rent_csv_data = RentCsvData(rent_data_csv_file)\n",
    "rent_csv_data.load_csv_file()\n",
    "rent_csv_data.process_csv_data()\n",
    "repaired_rows = rent_csv_data.check_and_repair_datetimes()\n",
    "if len(repaired_rows) > 0:\n",
    "    print(\"    Repaired datetimes at rows {}.\".format(repaired_rows))\n",
    "print(\"    Loaded and compiled rent CSV data with shape {}.\".format(rent_csv_data.df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geocoded addresses.\n",
    "print(\"Loading geocoded HDB addresses from {}.\".format(processed_data_dir / hdb_addresses_json_file))\n",
    "hdb_addresses = GeocodedAddresses()\n",
    "hdb_addresses.read_json(processed_data_dir / hdb_addresses_json_file)\n",
    "print(\"    Loaded {} existing geocoded addresses.\".format(len(hdb_addresses.df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for new addresses to be geocoded.\n",
    "all_unique_addresses = set(csv_data.df[\"address\"].unique())\n",
    "if rent_data_csv_file is not None:\n",
    "    all_unique_addresses.update(set(rent_csv_data.df[\"address\"].unique()))\n",
    "all_unique_geocoded_addresses = hdb_addresses.get_all_geocoded_addresses()\n",
    "\n",
    "# Update new geocoded addresses.\n",
    "missing_addresses = all_unique_addresses.difference(all_unique_geocoded_addresses)\n",
    "print(\"Found {} new addresses to be geocoded in the CSV data.\".format(len(missing_addresses)))\n",
    "if len(missing_addresses) > 0:\n",
    "    for ma in missing_addresses:\n",
    "        print(\"    {}\".format(ma))\n",
    "\n",
    "    hdb_addresses.update_geocoded_addresses(missing_addresses, country_codes = [\"sg\"])\n",
    "    hdb_addresses.to_json(processed_data_dir / hdb_addresses_json_file)\n",
    "    print(\"    Updated {} new geocoded HDB addresses.\".format(len(missing_addresses)))\n",
    "\n",
    "# Check for problematic geocodes.\n",
    "problem_addresses = hdb_addresses.verify_geocoded_latitudes_and_longitudes(country = \"SINGAPORE\")\n",
    "if len(problem_addresses) > 0:\n",
    "    print(\"Warning - the following {} addresses do not seem to have been geocoded correctly.\".format(\n",
    "        len(problem_addresses))\n",
    "    )\n",
    "    for i, p in enumerate(problem_addresses):\n",
    "        print(\"    {:05d}: {}.\".format(i, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge geocoded addresses with the resale flat prices CSV data.\n",
    "geocode_df = hdb_addresses.df[[\"address\", \"geometry\"]]\n",
    "\n",
    "csv_df = csv_data.get_df()\n",
    "processed_data_df = pd.merge(left=csv_df, right=geocode_df, left_on=\"address\", right_on=\"address\", how=\"left\")\n",
    "processed_data_df = geopandas.GeoDataFrame(processed_data_df)\n",
    "processed_data_df.crs = geocode_df.crs\n",
    "\n",
    "# Merge geocoded addresses with the rent CSV data.\n",
    "rent_csv_df = rent_csv_data.get_df()\n",
    "processed_rent_data_df = pd.merge(left=rent_csv_df, right=geocode_df, left_on=\"address\", right_on=\"address\", how=\"left\")\n",
    "processed_rent_data_df = geopandas.GeoDataFrame(processed_rent_data_df)\n",
    "processed_rent_data_df.crs = geocode_df.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce disk and memory usage by collapsing all polygons to centroid points.\n",
    "\n",
    "convert_polygons_to_centroids = True\n",
    "\n",
    "if convert_polygons_to_centroids is True:\n",
    "    processed_data_df[\"geometry\"] = processed_data_df[\"geometry\"].apply(lambda x: x.centroid)\n",
    "    processed_rent_data_df[\"geometry\"] = processed_rent_data_df[\"geometry\"].apply(lambda x: x.centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(processed_data_df.head())\n",
    "print(processed_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(processed_rent_data_df.head())\n",
    "print(processed_rent_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the merged processed resale flat prices data to disk.\n",
    "out_path = processed_data_dir / output_resale_geojson_file\n",
    "print(\"Saving processed resale flat prices data to {}.\".format(out_path))\n",
    "if output_resale_geojson_file.suffix == \".zip\":\n",
    "    processed_data_df.to_csv(out_path, index=False, compression=\"zip\")\n",
    "elif output_resale_geojson_file.suffix == \".json\":\n",
    "    processed_data_df.to_file(out_path, driver=\"GeoJSON\")\n",
    "elif output_resale_geojson_file.suffix == \".parquet\":\n",
    "    processed_data_df.to_parquet(out_path, index=False, compression=\"brotli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: output the merged processed rent data to disk:\n",
    "out_path = processed_data_dir / output_rent_geojson_file\n",
    "print(\"Saving processed rent data to {}.\".format(out_path))\n",
    "if output_rent_geojson_file.suffix == \".zip\":\n",
    "    processed_rent_data_df.to_csv(out_path, index=False, compression=\"zip\")\n",
    "elif output_rent_geojson_file.suffix == \".json\":\n",
    "    processed_rent_data_df.to_file(out_path, driver=\"GeoJSON\")\n",
    "elif output_rent_geojson_file.suffix == \".parquet\":\n",
    "    processed_rent_data_df.to_parquet(out_path, index=False, compression=\"brotli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
