{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Indexing\n",
    "\n",
    "Jupyter notebook version of `tools.price_indexing.py`. \n",
    "\n",
    "Price indexing indexes the median resale and rent prices for each month, using the latest month as the normalizing value. This enables us to track how the median resale and rent prices change in the past with respect to the latest month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from resale_flat_prices.linear_inversion.linear_inversion import LinearInversion\n",
    "from resale_flat_prices.resale_flat_data.resale_flat_data import ResaleFlatData\n",
    "from resale_flat_prices.resale_flat_data.rent_prices_data import RentPricesData\n",
    "\n",
    "\n",
    "# Data directories.\n",
    "csv_data_dir = Path(\"../data/ResaleFlatPrices/\")\n",
    "processed_data_dir = Path(\"../data/processed_data/\")\n",
    "\n",
    "\n",
    "resale_data_csv_file = \"resale-flat-prices.parquet\"\n",
    "output_resale_data_csv_file = \"resale-flat-prices-indexed.parquet\"\n",
    "\n",
    "rent_data_csv_file = \"rent-prices.parquet\"\n",
    "output_rent_data_csv_file = \"rent-prices-indexed.parquet\"\n",
    "\n",
    "price_column = \"price_per_sqft\"\n",
    "rent_column = \"monthly_rent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resale flat data.\n",
    "resale_flat_data = ResaleFlatData(processed_data_dir / resale_data_csv_file)\n",
    "resale_flat_data.read_parquet()\n",
    "resale_flat_data.df = resale_flat_data.df.sort_values([\"datetime\", \"town\"])\n",
    "\n",
    "unique_street_names = sorted(list(resale_flat_data.df[\"street_name\"].unique()))\n",
    "\n",
    "min_datetime = resale_flat_data.df[\"datetime\"].min()\n",
    "max_datetime = resale_flat_data.df[\"datetime\"].max()\n",
    "min_year = min_datetime.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rent price data.\n",
    "if rent_data_csv_file is not None:\n",
    "    rent_data = RentPricesData(processed_data_dir / rent_data_csv_file)\n",
    "    rent_data.read_parquet()\n",
    "    rent_data.df = rent_data.df.sort_values([\"datetime\", \"town\"])\n",
    "    \n",
    "    unique_street_names = sorted(unique_street_names + list(rent_data.df[\"street_name\"].unique()))\n",
    "\n",
    "    min_datetime = max(min_datetime, rent_data.df[\"datetime\"].min())\n",
    "    max_datetime = max(max_datetime, rent_data.df[\"datetime\"].max())\n",
    "    min_year = int(max([min_year, rent_data.df[\"datetime\"].min().year]))\n",
    "\n",
    "    rent_data.df = rent_data.df[rent_data.df[\"datetime\"].apply(lambda x: x.year) >= min_year]\n",
    "else:\n",
    "    rent_data = None\n",
    "\n",
    "resale_flat_data.df = resale_flat_data.df[resale_flat_data.df[\"datetime\"].apply(lambda x: x.year) >= min_year]\n",
    "\n",
    "print(\"Loaded resale_flat_data.df.shape: {}.\".format(resale_flat_data.df.shape))\n",
    "if rent_data is not None:\n",
    "    print(\"Loaded rent_data.df.shape: {}.\".format(rent_data.df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make time series.\n",
    "datetime_df = pd.DataFrame(\n",
    "    {\"datetime\": np.arange(min_datetime, max_datetime + np.timedelta64(31, \"D\"), dtype = 'datetime64[M]')}\n",
    ")\n",
    "datetime_df[\"X\"] = np.arange(1, len(datetime_df) + 1, 1) / len(datetime_df)\n",
    "\n",
    "dfs = {}\n",
    "dfs_rent = {}\n",
    "for s in unique_street_names:\n",
    "    if np.sum(resale_flat_data.df[\"street_name\"] == s) > 0:\n",
    "        dfs[s] = resale_flat_data.df[resale_flat_data.df[\"street_name\"] == s]\n",
    "        dfs[s] = dfs[s][[\"datetime\", price_column]].groupby([\"datetime\"]).median().reset_index()\n",
    "        dfs[s] = pd.merge(\n",
    "            datetime_df, dfs[s], left_on = [\"datetime\"], right_on = [\"datetime\"], how = \"left\"\n",
    "        )\n",
    "        dfs[s] = dfs[s].dropna()\n",
    "\n",
    "    if rent_data is not None:\n",
    "        if np.sum(rent_data.df[\"street_name\"] == s) > 0:\n",
    "            dfs_rent[s] = rent_data.df[rent_data.df[\"street_name\"] == s]\n",
    "            dfs_rent[s] = dfs_rent[s][[\"datetime\", rent_column]].groupby([\"datetime\"]).median().reset_index()\n",
    "            dfs_rent[s] = pd.merge(\n",
    "                datetime_df, dfs_rent[s], left_on = [\"datetime\"], right_on = [\"datetime\"], how = \"left\"\n",
    "            )\n",
    "            dfs_rent[s] = dfs_rent[s].dropna()\n",
    "\n",
    "print(\"{} unique resale street names.\".format(len(dfs.keys())))\n",
    "if rent_data is not None:\n",
    "    print(\"{} unique rent street names.\".format(len(dfs_rent.keys())))\n",
    "\n",
    "X_pred_months = datetime_df[\"datetime\"].values.astype(\"datetime64[M]\")\n",
    "X_pred = datetime_df[\"X\"].values\n",
    "X_pred = X_pred.reshape(-1, 1)\n",
    "\n",
    "future_months = 1\n",
    "for i in range(future_months):\n",
    "    X_pred_months = np.hstack([X_pred_months, X_pred_months[-1] + 1])\n",
    "    X_pred = np.vstack([X_pred, X_pred[-1] + (X_pred[-1] - X_pred[-2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resale price indexing model training.\n",
    "n_estimators = 50\n",
    "max_depth = 2\n",
    "min_samples_leaf = 2\n",
    "max_depth_low_data = 1\n",
    "low_data_threshold = 10\n",
    "criterion = \"absolute_error\"\n",
    "\n",
    "models = {}\n",
    "y_preds = {}\n",
    "scores = {}\n",
    "for k in dfs.keys():\n",
    "    y = dfs[k][\"price_per_sqft\"].values\n",
    "    X = dfs[k][\"X\"].values.reshape(-1, 1)\n",
    "    if len(y) >= low_data_threshold:\n",
    "        models[k] = RandomForestRegressor(\n",
    "            n_estimators=n_estimators, max_depth=max_depth, criterion=criterion, min_samples_leaf=min_samples_leaf,\n",
    "        )\n",
    "        #models[k] = LinearInversion(error_type=\"l1\", vander_order=3)\n",
    "    else:\n",
    "        models[k] = RandomForestRegressor(\n",
    "            n_estimators=n_estimators, max_depth=max_depth_low_data, criterion=criterion, min_samples_leaf=min_samples_leaf,\n",
    "        )\n",
    "        #models[k] = LinearInversion(error_type=\"l2\", vander_order=2)\n",
    "\n",
    "    models[k].fit(X, y)\n",
    "    y_pred = models[k].predict(X)\n",
    "    dfs[k][\"prediction\"] = y_pred\n",
    "    y_pred = y_pred / y_pred[-1]\n",
    "    dfs[k][\"price_index\"] = y_pred\n",
    "    y_preds[k] = models[k].predict(X_pred)\n",
    "    scores[k] = r2_score(y, models[k].predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rent indexing model training.\n",
    "if rent_data is not None:\n",
    "    models_rent = {}\n",
    "    y_preds_rent = {}\n",
    "    scores_rent = {}\n",
    "    for k in dfs_rent.keys():\n",
    "        y = dfs_rent[k][rent_column].values\n",
    "        X = dfs_rent[k][\"X\"].values.reshape(-1, 1)\n",
    "        if len(y) >= low_data_threshold:\n",
    "            models_rent[k] = RandomForestRegressor(\n",
    "                n_estimators=n_estimators, max_depth=max_depth, criterion=criterion, min_samples_leaf=min_samples_leaf,\n",
    "            )\n",
    "            #models_rent[k] = LinearInversion(error_type=\"l1\", vander_order=3)\n",
    "        else:\n",
    "            models_rent[k] = RandomForestRegressor(\n",
    "                n_estimators=n_estimators, max_depth=max_depth_low_data, criterion=criterion, min_samples_leaf=min_samples_leaf,\n",
    "            )\n",
    "            #models_rent[k] = LinearInversion(error_type=\"l2\", vander_order=2)\n",
    "\n",
    "        models_rent[k].fit(X, y)\n",
    "        y_pred = models_rent[k].predict(X)\n",
    "        dfs_rent[k][\"prediction\"] = y_pred\n",
    "        y_pred = y_pred / y_pred[-1]\n",
    "        dfs_rent[k][\"rent_index\"] = y_pred\n",
    "        y_preds_rent[k] = models_rent[k].predict(X_pred)\n",
    "        scores_rent[k] = r2_score(y, models_rent[k].predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update price DataFrames with price indexes.\n",
    "price_index_df = pd.DataFrame()\n",
    "for k in dfs.keys():\n",
    "    _df = dfs[k][[\"datetime\", \"price_index\"]].copy()\n",
    "    _df[\"street_name\"] = k\n",
    "    price_index_df = pd.concat([price_index_df, _df])\n",
    "\n",
    "if rent_data is not None:\n",
    "    rent_index_df = pd.DataFrame()\n",
    "    for k in dfs_rent.keys():\n",
    "        _df = dfs_rent[k][[\"datetime\", \"rent_index\"]].copy()\n",
    "        _df[\"street_name\"] = k\n",
    "        rent_index_df = pd.concat([rent_index_df, _df])\n",
    "\n",
    "resale_flat_data_indexed_df = resale_flat_data.df.merge(\n",
    "    price_index_df, \n",
    "    how = \"left\", \n",
    "    left_on=[\"datetime\", \"street_name\"],\n",
    "    right_on=[\"datetime\", \"street_name\"],\n",
    ")\n",
    "assert len(resale_flat_data.df) == len(resale_flat_data_indexed_df)\n",
    "\n",
    "if rent_data is not None:\n",
    "    rent_data_indexed_df = rent_data.df.merge(\n",
    "        rent_index_df,\n",
    "        how = \"left\",\n",
    "        left_on=[\"datetime\", \"street_name\"],\n",
    "        right_on=[\"datetime\", \"street_name\"],\n",
    "    )\n",
    "    assert len(rent_data.df) == len(rent_data_indexed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([scores[k] for k in scores.keys()], bins = 10, alpha = 0.5)\n",
    "if rent_data is not None:\n",
    "    plt.hist([scores_rent[k] for k in scores_rent.keys()], bins = 10, alpha = 0.5)\n",
    "plt.xlabel(\"R2 scores\")\n",
    "plt.ylabel(\"Histogram\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_resale_r2 = 0\n",
    "N = 0\n",
    "for k in dfs.keys():\n",
    "    if not np.isnan(scores[k]):\n",
    "        aggregated_resale_r2 = aggregated_resale_r2 + scores[k] * len(dfs[k][price_column].values)\n",
    "        N = N + len(dfs[k][price_column].values)\n",
    "aggregated_resale_r2 = aggregated_resale_r2 / N\n",
    "print(\"Resale price R2: {:.3f}.\".format(aggregated_resale_r2))\n",
    "\n",
    "if rent_data is not None:\n",
    "    aggregated_rent_r2 = 0\n",
    "    N = 0\n",
    "    for k in dfs_rent.keys():\n",
    "        if not np.isnan(scores_rent[k]):\n",
    "            aggregated_rent_r2 = aggregated_rent_r2 + scores_rent[k] * len(dfs_rent[k][rent_column].values)\n",
    "            N = N + len(dfs_rent[k][rent_column].values)\n",
    "    aggregated_rent_r2 = aggregated_rent_r2 / N\n",
    "    print(\"Rent price R2:   {:.3f}.\".format(aggregated_rent_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.array(sorted(list(set([k for k in scores.keys()] + [k for k in scores_rent.keys()]))))\n",
    "r2_resale = np.array([scores.get(k, np.nan) for k in keys])\n",
    "r2_rent = np.array([scores_rent.get(k, np.nan) for k in keys])\n",
    "\n",
    "plt.figure(figsize = [20, 5])\n",
    "plt.plot(r2_resale)\n",
    "plt.plot(r2_rent)\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=270)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keys[r2_resale < 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keys[r2_rent < 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = [15, 5])\n",
    "_df = resale_flat_data_indexed_df[[\"datetime\", \"price_index\"]].groupby([\"datetime\"]).median().reset_index()\n",
    "plt.plot(_df[\"datetime\"], _df[\"price_index\"], \"k\", linewidth=2)\n",
    "\n",
    "_df = rent_data_indexed_df[[\"datetime\", \"rent_index\"]].groupby([\"datetime\"]).median().reset_index()\n",
    "plt.plot(_df[\"datetime\"], _df[\"rent_index\"], \"r\", linewidth=2)\n",
    "\n",
    "for k in dfs.keys():\n",
    "    plt.plot(dfs[k][\"datetime\"], dfs[k][\"price_index\"], \"tab:gray\", alpha = 0.5)\n",
    "for k in dfs_rent.keys():\n",
    "    plt.plot(dfs_rent[k][\"datetime\"], dfs_rent[k][\"rent_index\"], \"tab:pink\", alpha = 0.5)\n",
    "\n",
    "_df = resale_flat_data_indexed_df[[\"datetime\", \"price_index\"]].groupby([\"datetime\"]).median().reset_index()\n",
    "plt.plot(_df[\"datetime\"], _df[\"price_index\"], \"k\", linewidth=2)\n",
    "\n",
    "_df = rent_data_indexed_df[[\"datetime\", \"rent_index\"]].groupby([\"datetime\"]).median().reset_index()\n",
    "plt.plot(_df[\"datetime\"], _df[\"rent_index\"], \"r\", linewidth=2)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend([\"Resale index\", \"Rent index\"])\n",
    "plt.xlabel(\"Datetime\")\n",
    "plt.ylabel(\"Normalized index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Price indices:\")\n",
    "for k in dfs.keys():\n",
    "    if dfs[k][\"price_index\"].max() > 1.4:\n",
    "        print(\"{}: {:.3f}.\".format(k, dfs[k][\"price_index\"].max()))\n",
    "    elif dfs[k][\"price_index\"].min() < 0.5:\n",
    "        print(\"{}: {:.3f}.\".format(k, dfs[k][\"price_index\"].min()))\n",
    "\n",
    "print(\"\\nRent indices:\")\n",
    "for k in dfs_rent.keys():\n",
    "    if dfs_rent[k][\"rent_index\"].max() > 1.4:\n",
    "        print(\"{}: {:.3f}.\".format(k, dfs_rent[k][\"rent_index\"].max()))\n",
    "    elif dfs_rent[k][\"rent_index\"].min() < 0.5:\n",
    "        print(\"{}: {:.3f}.\".format(k, dfs_rent[k][\"rent_index\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = \"TANGLIN HALT ROAD\"\n",
    "\n",
    "\n",
    "plt.figure(figsize = [15, 5])\n",
    "plt.subplot(2, 1, 1)\n",
    "if dfs.get(k, None) is not None:\n",
    "    plt.plot(dfs[k][\"datetime\"], dfs[k][price_column], \"o\")\n",
    "    plt.plot(X_pred_months, y_preds[k])\n",
    "\n",
    "plt.legend([\"Price data\", \"Price prediction\"])\n",
    "plt.grid(True)\n",
    "plt.title(k)\n",
    "plt.ylabel(price_column)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(dfs_rent[k][\"datetime\"], dfs_rent[k][rent_column], \"o\")\n",
    "plt.plot(X_pred_months, y_preds_rent[k])\n",
    "\n",
    "plt.legend([\"Rent data\", \"Rent prediction\"])\n",
    "plt.grid(True)\n",
    "plt.ylabel(rent_column)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output indexed prices to disk.\n",
    "save_to_disk = False\n",
    "\n",
    "parquet_compression = \"brotli\"\n",
    "\n",
    "if save_to_disk is True:\n",
    "    # Output the merged processed resale flat prices data to disk.\n",
    "    out_path = processed_data_dir / output_resale_data_csv_file\n",
    "    print(\"Saving processed resale flat prices data to {}.\".format(out_path))\n",
    "    if out_path.suffix == \".zip\":\n",
    "        resale_flat_data_indexed_df.to_csv(out_path, index=False, compression=\"zip\")\n",
    "    elif out_path.suffix == \".json\":\n",
    "        resale_flat_data_indexed_df.to_file(out_path, driver=\"GeoJSON\")\n",
    "    elif out_path.suffix == \".parquet\":\n",
    "        resale_flat_data_indexed_df.to_parquet(out_path, index=False, compression=parquet_compression)\n",
    "\n",
    "    # Optional: output the merged processed rent data to disk:\n",
    "    if rent_data_csv_file is not None:\n",
    "        out_path = processed_data_dir / output_rent_data_csv_file\n",
    "        print(\"Saving processed rent data to {}.\".format(out_path))\n",
    "        if out_path.suffix == \".zip\":\n",
    "            rent_data_indexed_df.to_csv(out_path, index=False, compression=\"zip\")\n",
    "        elif out_path.suffix == \".json\":\n",
    "            rent_data_indexed_df.to_file(out_path, driver=\"GeoJSON\")\n",
    "        elif out_path.suffix == \".parquet\":\n",
    "            rent_data_indexed_df.to_parquet(out_path, index=False, compression=parquet_compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
