{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Private Residential Landed Raw Data Pipeline\n",
    "\n",
    "Processes the raw private residential landed property transaction data downloaded from https://www.ura.gov.sg/property-market-information/pmiResidentialTransactionSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import geopandas\n",
    "\n",
    "# Local imports.\n",
    "from property_prices.transaction_csv_data.private_csv_data import PrivateCsvData\n",
    "from property_prices.geocode.geocoded_addresses import GeocodedAddresses\n",
    "\n",
    "\n",
    "# Data directories and files.\n",
    "csv_data_dir = Path(\"../data/PrivateResidentialPropertiesCondo/\")\n",
    "processed_data_dir = Path(\"../data/processed_data/\")\n",
    "\n",
    "landed_addresses_json_file = Path(\"condo_addresses.json\")\n",
    "output_landed_geojson_file = Path(\"condo_transactions.parquet\")\n",
    "\n",
    "private_residential_property_type = \"Condominium\"\n",
    "\n",
    "geocoder_service = \"arcgis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transaction CSV data.\n",
    "print(\"Loading landed properties transactions CSV data from {}.\".format(csv_data_dir))\n",
    "\n",
    "private_csv_data = PrivateCsvData(csv_data_dir, wanted_columns = \"default\")\n",
    "private_csv_data.load_csv_files()\n",
    "private_csv_data.process_csv_data()\n",
    "\n",
    "display(private_csv_data.df.head())\n",
    "print(\"    Loaded landed properties CSV data with shape {}.\".format(private_csv_data.df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geocoded addresses.\n",
    "geocoded_addresses = GeocodedAddresses(geocoder=geocoder_service)\n",
    "if (processed_data_dir / landed_addresses_json_file).exists() is True:\n",
    "    print(\"Loading geocoded HDB addresses from {}.\".format(processed_data_dir / landed_addresses_json_file))\n",
    "    geocoded_addresses.read_json(processed_data_dir / landed_addresses_json_file)\n",
    "    print(\"    Loaded {} existing geocoded addresses.\".format(len(geocoded_addresses.df)))\n",
    "\n",
    "# Check for new addresses to be geocoded.\n",
    "if private_residential_property_type.lower() == \"landed\":\n",
    "    all_unique_addresses = set(private_csv_data.df[\"street_name\"].unique())\n",
    "else:\n",
    "    # For condominiums and apartments, join the project name with the street name.\n",
    "    all_unique_addresses = set(\n",
    "        private_csv_data.df[\"project_name\"] + \", \" + private_csv_data.df[\"street_name\"]\n",
    "    )\n",
    "\n",
    "all_unique_geocoded_addresses = geocoded_addresses.get_all_geocoded_addresses()\n",
    "missing_addresses = all_unique_addresses.difference(all_unique_geocoded_addresses)\n",
    "missing_addresses = list(missing_addresses)\n",
    "if private_residential_property_type.lower() != \"landed\":\n",
    "    missing_addresses = sorted([s + \", SINGAPORE\" for s in missing_addresses])\n",
    "else:\n",
    "    missing_addresses = sorted(missing_addresses)\n",
    "\n",
    "print(\"Found {} new addresses to be geocoded in the CSV data.\".format(len(missing_addresses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update missing geocoded addresses.\n",
    "if len(missing_addresses) > 0:\n",
    "    #for i, ma in enumerate(missing_addresses):\n",
    "    #    print(\"    {}: {}\".format(i+1, ma))\n",
    "    error_address_list = geocoded_addresses.update_geocoded_addresses(missing_addresses)\n",
    "    # Output geocoded addresses to disk.\n",
    "    geocoded_addresses.to_json(processed_data_dir / landed_addresses_json_file)\n",
    "    print(\"    Updated {} new geocoded HDB addresses.\".format(len(missing_addresses) - len(error_address_list)))\n",
    "\n",
    "    if len(error_address_list) > 0:\n",
    "        print(\"    The following addresses were not geocoded: {}\".format(error_address_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for problematic geocoded addresses (e.g. coordinates located outside Singapore!).\n",
    "problem_addresses = geocoded_addresses.verify_geocoded_latitudes_and_longitudes(country = \"SINGAPORE\")\n",
    "if len(problem_addresses) > 0:\n",
    "    print(\"Warning - the following {} addresses do not seem to have been geocoded correctly.\".format(\n",
    "        len(problem_addresses))\n",
    "    )\n",
    "    for i, p in enumerate(problem_addresses):\n",
    "        print(\"    {:05d}: {}.\".format(i, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge geocoded addresses with the resale flat prices CSV data.\n",
    "geocode_df = geocoded_addresses.df[[\"address\", \"geometry\"]]\n",
    "geocode_df = geocode_df.rename(columns={\"address\": \"street_name\"})\n",
    "\n",
    "private_csv_df = private_csv_data.get_df()\n",
    "processed_data_df = pd.merge(left=private_csv_df, right=geocode_df, left_on=\"street_name\", right_on=\"street_name\", how=\"left\")\n",
    "processed_data_df = geopandas.GeoDataFrame(processed_data_df)\n",
    "processed_data_df.crs = geocode_df.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(processed_data_df.head())\n",
    "print(processed_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the merged processed resale flat prices data to disk.\n",
    "out_path = processed_data_dir / output_landed_geojson_file\n",
    "print(\"Saving processed resale flat prices data to {}.\".format(out_path))\n",
    "if output_landed_geojson_file.suffix == \".zip\":\n",
    "    processed_data_df.to_csv(out_path, index=False, compression=\"zip\")\n",
    "elif output_landed_geojson_file.suffix == \".json\":\n",
    "    processed_data_df.to_file(out_path, driver=\"GeoJSON\")\n",
    "elif output_landed_geojson_file.suffix == \".parquet\":\n",
    "    processed_data_df.to_parquet(out_path, index=False, compression=\"brotli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
